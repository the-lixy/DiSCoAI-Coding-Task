{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOXL+G6uGuNNG8Sa+3uR6v+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/the-lixy/DiSCoAI-Coding-Task/blob/main/DiSCoAICodingTaskStreamlit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yUQ12Yn124-",
        "outputId": "fd8ebd7a-6329-40d0-b077-a4f80c30277c",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.7)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.16.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.13.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.4.26)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting textsearch>=0.0.21 (from contractions)\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
            "  Downloading anyascii-0.3.2-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
            "  Downloading pyahocorasick-2.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyahocorasick-2.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.3/118.3 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.1.0 textsearch-0.0.24\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m105.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Collecting openai==0.28.1\n",
            "  Downloading openai-0.28.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from openai==0.28.1) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai==0.28.1) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from openai==0.28.1) (3.11.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28.1) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28.1) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28.1) (2025.4.26)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.1) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.1) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.1) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.1) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.1) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.1) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.1) (1.20.0)\n",
            "Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.82.1\n",
            "    Uninstalling openai-1.82.1:\n",
            "      Successfully uninstalled openai-1.82.1\n",
            "Successfully installed openai-0.28.1\n",
            "Collecting streamlit\n",
            "  Downloading streamlit-1.45.1-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.24.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.41.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.4.26)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.25.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.45.1-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.45.1 watchdog-6.0.0\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K\n",
            "added 22 packages in 2s\n",
            "\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K"
          ]
        }
      ],
      "source": [
        "!pip install spacy\n",
        "!pip install contractions\n",
        "!python -m spacy download en_core_web_sm\n",
        "!pip install openai==0.28.1\n",
        "!pip install streamlit\n",
        "!npm install -g localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('GPTkey')"
      ],
      "metadata": {
        "id": "DuIPgeY5GEAr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile DiSCoAIapp.py\n",
        "import streamlit as st\n",
        "import contractions\n",
        "import spacy\n",
        "from spacy.matcher import PhraseMatcher\n",
        "import re\n",
        "import os\n",
        "from google.colab import userdata\n",
        "import openai\n",
        "\n",
        "\n",
        "st.title(\"Dialogue Function Classifier\")\n",
        "st.write(\"Please upload dialogue as a .txt file: \")\n",
        "\n",
        "# file uploader widget\n",
        "uploaded_file = st.file_uploader(\"Choose a file\", type=[\"txt\"])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "  filename = uploaded_file.name\n",
        "\n",
        "  # punctuation removal using regex\n",
        "  def remove_punctuation(text):\n",
        "      return re.sub(r'[^\\w\\s\\?]', '', text)\n",
        "\n",
        "  # parse dialogue to separate speaker and utterance\n",
        "  rawUtterances = []\n",
        "  utterances = []\n",
        "  f = uploaded_file.read().decode(\"utf-8\")\n",
        "  lines = f.splitlines()\n",
        "  for line in lines:\n",
        "      line = line.strip()\n",
        "      if \":\" in line:\n",
        "          speaker, utterance = line.split(\":\", 1)\n",
        "          speaker = speaker.strip()\n",
        "          rawUtterances.append((speaker, utterance))\n",
        "          # normalisation steps - lowercase, noise removal, contraction expansion, remove punctuation\n",
        "          utterance = utterance.strip().lower()\n",
        "          utterance = contractions.fix(utterance)\n",
        "          utterance = remove_punctuation(utterance)\n",
        "          utterances.append((speaker, utterance))\n",
        "\n",
        "  # display original dialogue turns\n",
        "  st.write(\"Original Dialogue:\")\n",
        "  for i, (speaker, utterance) in enumerate(utterances):\n",
        "    st.write(speaker + \": \" + rawUtterances[i][1])\n",
        "\n",
        "  # (testing only) display normalised dialogue turns\n",
        "  #st.write(\"Normalised Dialogue:\")\n",
        "  #for i, (speaker, utterance) in enumerate(utterances):\n",
        "    #st.write(speaker + \": \" + utterances[i][1])\n",
        "\n",
        "  nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "  subjects = [\"i\", \"you\", \"we\", \"he\", \"she\", \"they\", \"us\"]\n",
        "\n",
        "  commitment_phrases = [\n",
        "      \"will\", \"shall\", \"must\", \"ought to\", \"have to\",\n",
        "      \"going to\", \"gotta\", \"intend to\", \"promise to\", \"swear to\", \"vow to\",\n",
        "      \"guarantee\", \"commit to\"\n",
        "  ]\n",
        "\n",
        "  proposal_phrases = [\n",
        "      \"should\", \"could\", \"would\", \"may\", \"might\", \"{subject} can\",\n",
        "      \"can possibly\", \"can perhaps\",\n",
        "      \"recommend\", \"suggest\", \"advise\",\n",
        "      \"consider\", \"plan to\", \"aim to\", \"hope to\",\n",
        "      \"wish to\", \"try to\",\n",
        "      \"supposed to\", \"expected to\",\n",
        "      \"would like to\", \"let us\"\n",
        "  ]\n",
        "\n",
        "  justification_phrases = [\n",
        "      \"because\", \"since\", \"due to\", \"as a result of\", \"true but\", \"yes but\",\n",
        "      \"therefore\", \"thus\", \"consequently\", \"for this reason\"\n",
        "  ]\n",
        "\n",
        "  query_phrases = [\n",
        "      \"can {subject}\", \"could {subject}\", \"would {subject}\", \"will {subject}\", \"may {subject}\",\n",
        "      \"might {subject}\", \"would {subject} mind\", \"do {subject} know\", \"can {subject}\", \"could {subject}\",\n",
        "      \"is it possible\", \"may {subject}\", \"shall {subject}\"\n",
        "  ]\n",
        "\n",
        "  deferral_phrases = [\n",
        "      \"maybe\", \"perhaps\", \"possibly\", \"might be\", \"could be\", \"not yet\",\n",
        "      \"let us wait\", \"hold off\", \"postpone\", \"delay\",\n",
        "      \"put off\", \"wait and see\", \"hold on\", \"defer\", \"for now\", \"need to think\"\n",
        "  ]\n",
        "\n",
        "  challenge_phrases = [\n",
        "      \"why do not {subject}\", \"why does not {subject}\", \"not convinced\", \"how about\", \"what if\",\n",
        "      \"are not {subject}\", \"is not {subject}\", \"is not it\", \"do not {subject} think\", \"would not it be\",\n",
        "      \"could not {subject}\", \"shouldn't {subject}\", \"is it really\", \"are you sure\", \"i am not sure\"\n",
        "  ]\n",
        "\n",
        "  #add all subjects to phrase lists\n",
        "  challenge_phrases = [\n",
        "    phrase.format(subject=s) if \"{subject}\" in phrase else phrase\n",
        "    for phrase in challenge_phrases\n",
        "    for s in subjects\n",
        "  ]\n",
        "\n",
        "  defferal_phrases = [\n",
        "    phrase.format(subject=s) if \"{subject}\" in phrase else phrase\n",
        "    for phrase in deferral_phrases\n",
        "    for s in subjects\n",
        "  ]\n",
        "\n",
        "  query_phrases = [\n",
        "    phrase.format(subject=s) if \"{subject}\" in phrase else phrase\n",
        "    for phrase in query_phrases\n",
        "    for s in subjects\n",
        "  ]\n",
        "\n",
        "  proposal_phrases = [\n",
        "    phrase.format(subject=s) if \"{subject}\" in phrase else phrase\n",
        "    for phrase in proposal_phrases\n",
        "    for s in subjects\n",
        "  ]\n",
        "\n",
        "  commitment_phrases = [\n",
        "    phrase.format(subject=s) if \"{subject}\" in phrase else phrase\n",
        "    for phrase in commitment_phrases\n",
        "    for s in subjects\n",
        "  ]\n",
        "\n",
        "  justification_phrases = [\n",
        "    phrase.format(subject=s) if \"{subject}\" in phrase else phrase\n",
        "    for phrase in justification_phrases\n",
        "    for s in subjects\n",
        "  ]\n",
        "\n",
        "\n",
        "  matcher = PhraseMatcher(nlp.vocab, attr=\"LOWER\")\n",
        "\n",
        "  matcher.add(\"COMMITMENT\", [nlp(text) for text in commitment_phrases])\n",
        "  matcher.add(\"PROPOSAL\", [nlp(text) for text in proposal_phrases])\n",
        "  matcher.add(\"JUSTIFICATION\", [nlp(text) for text in justification_phrases])\n",
        "  matcher.add(\"QUERY\", [nlp(text) for text in query_phrases])\n",
        "  matcher.add(\"DEFERRAL\", [nlp(text) for text in deferral_phrases])\n",
        "  matcher.add(\"CHALLENGE\", [nlp(text) for text in challenge_phrases])\n",
        "\n",
        "  def categorize_most_confident_category(text):\n",
        "    doc = nlp(text)\n",
        "    matches = matcher(doc)\n",
        "\n",
        "    if \"?\" in text:\n",
        "        return {\"category\": \"query\", \"matches\": [\"?\"]}\n",
        "\n",
        "    counts = {\n",
        "        \"commitment\": 0,\n",
        "        \"proposal\": 0,\n",
        "        \"justification\": 0,\n",
        "        \"query\": 0,\n",
        "        \"deferral\": 0,\n",
        "        \"challenge\": 0\n",
        "    }\n",
        "    matched_phrases = {\n",
        "        \"commitment\": [],\n",
        "        \"proposal\": [],\n",
        "        \"justification\": [],\n",
        "        \"query\": [],\n",
        "        \"deferral\": [],\n",
        "        \"challenge\": []\n",
        "    }\n",
        "\n",
        "    for match_id, start, end in matches:\n",
        "        span = doc[start:end]\n",
        "        label = nlp.vocab.strings[match_id].lower()\n",
        "        counts[label] += 1\n",
        "        matched_phrases[label].append(span.text)\n",
        "\n",
        "    # find category with max matches\n",
        "    max_category = max(counts, key=counts.get)\n",
        "\n",
        "    # if no matches found, return \"statement\"\n",
        "    if counts[max_category] == 0:\n",
        "        return {\"category\": \"statement\", \"matches\": [\"none found\"]}\n",
        "\n",
        "    return {\"category\": max_category, \"matches\": matched_phrases[max_category]}\n",
        "\n",
        "    # classify all turns\n",
        "  classified = []\n",
        "  for _, utterance in utterances:\n",
        "      classified += [categorize_most_confident_category(utterance)]\n",
        "\n",
        "  # display a table of utterances and their classifications\n",
        "  import pandas as pd\n",
        "  results = []\n",
        "  for i, (speaker, _) in enumerate(utterances):\n",
        "      results.append({\n",
        "          \"Speaker\": speaker,\n",
        "          \"Utterance\": rawUtterances[i][1],\n",
        "          \"Function\": classified[i]['category'],\n",
        "          \"Reason\": \", \".join(f'\"{m}\"' for m in classified[i]['matches'])\n",
        "      })\n",
        "  df = pd.DataFrame(results)\n",
        "  st.table(df)  # or st.dataframe(df)\n",
        "\n",
        "\n",
        "  # format the results for passing to the LLM\n",
        "  i = 1\n",
        "  formattedResults = []\n",
        "  formattedResults.append(\"Speaker: \" + \"Utterance\" + \" | \" + \"Dialogue Function\")\n",
        "\n",
        "  for i, (speaker, utterance) in enumerate(utterances):\n",
        "    formattedResults.append(speaker + \": \" + rawUtterances[i][1] + \" | \" + classified[i]['category'] + \"\\n\")\n",
        "\n",
        "  api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "  if not api_key:\n",
        "      st.error(\"API key not found. Please set it in Colab before running the app.\")\n",
        "\n",
        "  # Task 2 - LLM\n",
        "  # make sure the API key is available\n",
        "  openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "  # request\n",
        "  response = openai.ChatCompletion.create(\n",
        "      model=\"gpt-4o-mini\",\n",
        "      messages=[\n",
        "          {\"role\": \"user\", \"content\":\n",
        "          \"Very briefly summarise this conversation in past-tense narrative format. You must always make reference to the supplied dialogue function (Proposal, Challenge, Commitment, Justification, Query, Deferral, or Statement) of each utterance. Do not include the actual dialogue. Do not make your own assumptions about the dialogue function of any utterances.\"\n",
        "          + str(formattedResults)}\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  st.write(response.choices[0].message[\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fH1G_DyoGIKm",
        "outputId": "41a8450d-082f-420e-e15a-227615bf4102"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting DiSCoAIapp.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import re\n",
        "\n",
        "# start streamlit app\n",
        "def run_streamlit():\n",
        "    subprocess.run([\"streamlit\", \"run\", \"DiSCoAIapp.py\"])\n",
        "\n",
        "threading.Thread(target=run_streamlit).start()\n",
        "\n",
        "# give Streamlit some time to boot\n",
        "time.sleep(5)\n",
        "\n",
        "# start localtunnel and capture output\n",
        "lt_process = subprocess.Popen(\n",
        "    ['lt', '--port', '8501', '--subdomain', 'albu-streamlit'],\n",
        "    stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.PIPE,\n",
        "    text=True\n",
        ")\n",
        "\n",
        "# read and display the public URL from localtunnel's output\n",
        "for line in lt_process.stdout:\n",
        "    if 'your url is:' in line:\n",
        "        url = re.search(r'(https://.*\\.loca\\.lt)', line)\n",
        "        if url:\n",
        "            print(\"Streamlit available at:\", url.group(1), \".\", \"Tunnel may ask you for a password, the cell below will show you the password.\")\n",
        "            break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiUXhAKgGIfy",
        "outputId": "df9bf14e-a6e7-4228-a898-dda41f2b13e5"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit available at: https://albu-streamlit.loca.lt . Tunnel may ask you for a password, the cell below will show you the password.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O - https://loca.lt/mytunnelpassword"
      ],
      "metadata": {
        "id": "XcEjkKk0GL-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# uncomment this to kill Streamlit and LocalTunnel processes\n",
        "#!pkill streamlit\n",
        "#!pkill lt"
      ],
      "metadata": {
        "id": "QyQoBCnbHQmE"
      },
      "execution_count": 29,
      "outputs": []
    }
  ]
}